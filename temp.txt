There are a couple of issues with the current strategy to write text predictions to a csv file and write associated metadata to a json file. Both output files are written to output/predictions that you can reference. The csv and json outputs are defined in the _prepare_results method in line 465 in the src/orchestrator.py file. 

The 3 issues are:
1. I want the metadata from the json files instead written to the csv file where each key in the json data is a column in the csv file
2. Record the actual pipeline that was used to get the predicted text for that row. Right now I think it is record one pipeline for all rows even if a row used a different pipeline to get its result. The preprocessing_methods column in the csv files needs to incude the full pipeline configuration as it is in the config/pipelines files. 
For instance, if I use easyocr.json as the pipeline config, and the predicted value we want to save is from the pipeline with retry_attempt=2, then we would enter it's "methods" value in the preprocessing_methods (rename to pipeline_steps) column of the predictions csv (here it is):
{
          "method": "grayscale",
          "parameters": null
        },
        {
          "method": "gaussian_blur",
          "parameters": {
            "kernel": [5,5],
            "sigmaX": 0,
            "sigmaY": 0
          }
        },
        {
          "method": "inversion",
          "parameters": null
        },
        {
          "method": "edge_detection",
          "parameters": {
            "hysteresis_min": 100,
            "hysteresis_max": 150
          }
        },
        {
          "method": "dilate",
          "parameters": {
            "kernel": [5,5]
          }
        },
        {
          "method": "erode",
          "parameters": {
            "kernel": [5,5]
          }
        }
3. 